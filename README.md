# Home_Sales

This project demonstrates the use of PySpark to calculate SQL queries in a large data set.  

## Overview of the Analysis

Many queries are demonstrated in the code. Also, three methods to read the data are used, and their run times calculated.  These are the initial run, a use of a cached dataframe, and a use of a parquet data frame. 
## Results
On my personal machine, the initial run was the fastest, with the parquet taking the longest.  

## Libraries 
Code is written in Python using Spark. 

## Author
Code written by Alana Castellano, with starter code provided by Data Analytics Bootcamp and Ariel Gamino.
